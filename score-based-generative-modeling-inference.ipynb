{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yang-song/score_sde_pytorch/blob/main/Score_SDE_demo_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBJappt3toqj"
      },
      "source": [
        "# Preparation\n",
        "\n",
        "1. `git clone https://github.com/yang-song/score_sde_pytorch.git`\n",
        "\n",
        "2. Install [required packages](https://github.com/yang-song/score_sde_pytorch/blob/main/requirements.txt)\n",
        "\n",
        "3. `cd` into folder `score_sde_pytorch`, launch a local jupyter server and connect to colab following [these instructions](https://research.google.com/colaboratory/local-runtimes.html)\n",
        "\n",
        "4. Download pre-trained [checkpoints](https://drive.google.com/drive/folders/1tFmF_uh57O6lx9ggtZT_5LdonVK2cV-e?usp=sharing) and save them in the `exp` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa9OIcJmUKmZ",
        "outputId": "8fde468b-2c95-4003-f0bd-20ddad5248e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-03 13:42:30.574282: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-05-03 13:42:30.627185: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-05-03 13:42:30.628386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 13:42:31.480668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "CUDA_HOME environment variable is not set. Please set it to your CUDA install root.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m utils \u001b[39mas\u001b[39;00m mutils\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m ncsnv2\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m ncsnpp\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m ddpm \u001b[39mas\u001b[39;00m ddpm_model\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m layerspp\n",
            "File \u001b[0;32m~/work/score_sde_pytorch/models/ncsnpp.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Copyright 2020 The Google Research Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[39m# pylint: skip-file\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m utils, layers, layerspp, normalization\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n",
            "File \u001b[0;32m~/work/score_sde_pytorch/models/layerspp.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m\"\"\"Layers for defining NCSN++.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m up_or_down_sampling\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
            "File \u001b[0;32m~/work/score_sde_pytorch/models/up_or_down_sampling.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mop\u001b[39;00m \u001b[39mimport\u001b[39;00m upfirdn2d\n\u001b[1;32m     13\u001b[0m \u001b[39m# Function ported from StyleGAN2\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_weight\u001b[39m(module,\n\u001b[1;32m     15\u001b[0m                shape,\n\u001b[1;32m     16\u001b[0m                weight_var\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m                kernel_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
            "File \u001b[0;32m~/work/score_sde_pytorch/op/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfused_act\u001b[39;00m \u001b[39mimport\u001b[39;00m FusedLeakyReLU, fused_leaky_relu\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mupfirdn2d\u001b[39;00m \u001b[39mimport\u001b[39;00m upfirdn2d\n",
            "File \u001b[0;32m~/work/score_sde_pytorch/op/fused_act.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcpp_extension\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n\u001b[1;32m     10\u001b[0m module_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m fused \u001b[39m=\u001b[39m load(\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     sources\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     14\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(module_path, \u001b[39m\"\u001b[39;49m\u001b[39mfused_bias_act.cpp\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     15\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(module_path, \u001b[39m\"\u001b[39;49m\u001b[39mfused_bias_act_kernel.cu\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     16\u001b[0m     ],\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mFusedLeakyReLUFunctionBackward\u001b[39;00m(Function):\n\u001b[1;32m     21\u001b[0m     \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, grad_output, out, negative_slope, scale):\n",
            "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1284\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(name,\n\u001b[1;32m   1193\u001b[0m          sources: Union[\u001b[39mstr\u001b[39m, List[\u001b[39mstr\u001b[39m]],\n\u001b[1;32m   1194\u001b[0m          extra_cflags\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m          is_standalone\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1203\u001b[0m          keep_intermediates\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1204\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[39m    Loads a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39m        ...     verbose=True)\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m-> 1284\u001b[0m     \u001b[39mreturn\u001b[39;00m _jit_compile(\n\u001b[1;32m   1285\u001b[0m         name,\n\u001b[1;32m   1286\u001b[0m         [sources] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(sources, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m sources,\n\u001b[1;32m   1287\u001b[0m         extra_cflags,\n\u001b[1;32m   1288\u001b[0m         extra_cuda_cflags,\n\u001b[1;32m   1289\u001b[0m         extra_ldflags,\n\u001b[1;32m   1290\u001b[0m         extra_include_paths,\n\u001b[1;32m   1291\u001b[0m         build_directory \u001b[39mor\u001b[39;49;00m _get_build_directory(name, verbose),\n\u001b[1;32m   1292\u001b[0m         verbose,\n\u001b[1;32m   1293\u001b[0m         with_cuda,\n\u001b[1;32m   1294\u001b[0m         is_python_module,\n\u001b[1;32m   1295\u001b[0m         is_standalone,\n\u001b[1;32m   1296\u001b[0m         keep_intermediates\u001b[39m=\u001b[39;49mkeep_intermediates)\n",
            "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1509\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                 hipified_sources\u001b[39m.\u001b[39madd(hipify_result[s_abs][\u001b[39m\"\u001b[39m\u001b[39mhipified_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m s_abs \u001b[39min\u001b[39;00m hipify_result \u001b[39melse\u001b[39;00m s_abs)\n\u001b[1;32m   1507\u001b[0m             sources \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(hipified_sources)\n\u001b[0;32m-> 1509\u001b[0m         _write_ninja_file_and_build_library(\n\u001b[1;32m   1510\u001b[0m             name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1511\u001b[0m             sources\u001b[39m=\u001b[39;49msources,\n\u001b[1;32m   1512\u001b[0m             extra_cflags\u001b[39m=\u001b[39;49mextra_cflags \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1513\u001b[0m             extra_cuda_cflags\u001b[39m=\u001b[39;49mextra_cuda_cflags \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1514\u001b[0m             extra_ldflags\u001b[39m=\u001b[39;49mextra_ldflags \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1515\u001b[0m             extra_include_paths\u001b[39m=\u001b[39;49mextra_include_paths \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1516\u001b[0m             build_directory\u001b[39m=\u001b[39;49mbuild_directory,\n\u001b[1;32m   1517\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1518\u001b[0m             with_cuda\u001b[39m=\u001b[39;49mwith_cuda,\n\u001b[1;32m   1519\u001b[0m             is_standalone\u001b[39m=\u001b[39;49mis_standalone)\n\u001b[1;32m   1520\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1521\u001b[0m     baton\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1601\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[39mif\u001b[39;00m with_cuda \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1600\u001b[0m     with_cuda \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\u001b[39mmap\u001b[39m(_is_cuda_file, sources))\n\u001b[0;32m-> 1601\u001b[0m extra_ldflags \u001b[39m=\u001b[39m _prepare_ldflags(\n\u001b[1;32m   1602\u001b[0m     extra_ldflags \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1603\u001b[0m     with_cuda,\n\u001b[1;32m   1604\u001b[0m     verbose,\n\u001b[1;32m   1605\u001b[0m     is_standalone)\n\u001b[1;32m   1606\u001b[0m build_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(build_directory, \u001b[39m'\u001b[39m\u001b[39mbuild.ninja\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1607\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n",
            "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1699\u001b[0m, in \u001b[0;36m_prepare_ldflags\u001b[0;34m(extra_ldflags, with_cuda, verbose, is_standalone)\u001b[0m\n\u001b[1;32m   1697\u001b[0m         extra_ldflags\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/LIBPATH:\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CUDNN_HOME,\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlib\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx64\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1698\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m IS_HIP_EXTENSION:\n\u001b[0;32m-> 1699\u001b[0m     extra_ldflags\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-L\u001b[39m\u001b[39m{\u001b[39;00m_join_cuda_home(\u001b[39m\"\u001b[39;49m\u001b[39mlib64\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1700\u001b[0m     extra_ldflags\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m-lcudart\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1701\u001b[0m     \u001b[39mif\u001b[39;00m CUDNN_HOME \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2223\u001b[0m, in \u001b[0;36m_join_cuda_home\u001b[0;34m(*paths)\u001b[0m\n\u001b[1;32m   2216\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m   2217\u001b[0m \u001b[39mJoins paths with CUDA_HOME, or raises an error if it CUDA_HOME is not set.\u001b[39;00m\n\u001b[1;32m   2218\u001b[0m \n\u001b[1;32m   2219\u001b[0m \u001b[39mThis is basically a lazy way of raising an error for missing $CUDA_HOME\u001b[39;00m\n\u001b[1;32m   2220\u001b[0m \u001b[39monly once we need to get any CUDA-specific path.\u001b[39;00m\n\u001b[1;32m   2221\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m   2222\u001b[0m \u001b[39mif\u001b[39;00m CUDA_HOME \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCUDA_HOME environment variable is not set. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2224\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mPlease set it to your CUDA install root.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2225\u001b[0m \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CUDA_HOME, \u001b[39m*\u001b[39mpaths)\n",
            "\u001b[0;31mOSError\u001b[0m: CUDA_HOME environment variable is not set. Please set it to your CUDA install root."
          ]
        }
      ],
      "source": [
        "#@title Autoload all modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import importlib\n",
        "import os\n",
        "import functools\n",
        "import itertools\n",
        "import torch\n",
        "from losses import get_optimizer\n",
        "from models.ema import ExponentialMovingAverage\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "import tqdm\n",
        "import io\n",
        "import likelihood\n",
        "import controllable_generation\n",
        "from utils import restore_checkpoint\n",
        "sns.set(font_scale=2)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "import models\n",
        "from models import utils as mutils\n",
        "from models import ncsnv2\n",
        "from models import ncsnpp\n",
        "from models import ddpm as ddpm_model\n",
        "from models import layerspp\n",
        "from models import layers\n",
        "from models import normalization\n",
        "import sampling\n",
        "from likelihood import get_likelihood_fn\n",
        "from sde_lib import VESDE, VPSDE, subVPSDE\n",
        "from sampling import (ReverseDiffusionPredictor, \n",
        "                      LangevinCorrector, \n",
        "                      EulerMaruyamaPredictor, \n",
        "                      AncestralSamplingPredictor, \n",
        "                      NoneCorrector, \n",
        "                      NonePredictor,\n",
        "                      AnnealedLangevinDynamics)\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-reedYgCU79v"
      },
      "outputs": [],
      "source": [
        "# @title Load the score-based model\n",
        "sde = 'VESDE' #@param ['VESDE', 'VPSDE', 'subVPSDE'] {\"type\": \"string\"}\n",
        "if sde.lower() == 'vesde':\n",
        "  from configs.ve import cifar10_ncsnpp_continuous as configs\n",
        "  ckpt_filename = \"exp/ve/mnist_ncsnpp/checkpoint.pth\"\n",
        "  config = configs.get_config()  \n",
        "  sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-5\n",
        "elif sde.lower() == 'vpsde':\n",
        "  from configs.vp import cifar10_ddpmpp_continuous as configs  \n",
        "  ckpt_filename = \"exp/vp/cifar10_ddpmpp_continuous/checkpoint_8.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "elif sde.lower() == 'subvpsde':\n",
        "  from configs.subvp import cifar10_ddpmpp_continuous as configs\n",
        "  ckpt_filename = \"exp/subvp/cifar10_ddpmpp_continuous/checkpoint_26.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = subVPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "\n",
        "batch_size =   64#@param {\"type\":\"integer\"}\n",
        "config.training.batch_size = batch_size\n",
        "config.eval.batch_size = batch_size\n",
        "\n",
        "random_seed = 0 #@param {\"type\": \"integer\"}\n",
        "\n",
        "sigmas = mutils.get_sigmas(config)\n",
        "scaler = datasets.get_data_scaler(config)\n",
        "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
        "score_model = mutils.create_model(config)\n",
        "\n",
        "optimizer = get_optimizer(config, score_model.parameters())\n",
        "ema = ExponentialMovingAverage(score_model.parameters(),\n",
        "                               decay=config.model.ema_rate)\n",
        "state = dict(step=0, optimizer=optimizer,\n",
        "             model=score_model, ema=ema)\n",
        "\n",
        "state = restore_checkpoint(ckpt_filename, state, config.device)\n",
        "ema.copy_to(score_model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "G8ei2Xsfg6JQ"
      },
      "outputs": [],
      "source": [
        "#@title Visualization code\n",
        "\n",
        "def image_grid(x):\n",
        "  size = config.data.image_size\n",
        "  channels = config.data.num_channels\n",
        "  img = x.reshape(-1, size, size, channels)\n",
        "  w = int(np.sqrt(img.shape[0]))\n",
        "  img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n",
        "  return img\n",
        "\n",
        "def show_samples(x):\n",
        "  x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "  img = image_grid(x)\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hbBGjCMNUsp"
      },
      "source": [
        "# Predictor Corrector sampling\n",
        "\n",
        "\n",
        "Recommended settings:\n",
        "\n",
        " | dataset | SDE | predictor | corrector | snr | n_steps |\n",
        "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
        "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
        "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
        "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
        "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
        "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |\n",
        "\n",
        "Check `probability_flow` to run PC sampling based on discretizing the probability flow ODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "_X41BhiLqJvM",
        "outputId": "8a5b3b5f-93ad-4baf-d66f-0a648f935170"
      },
      "outputs": [],
      "source": [
        "#@title PC sampling\n",
        "img_size = config.data.image_s\n",
        "ize\n",
        "channels = config.data.num_channels\n",
        "shape = (batch_size, channels, img_size, img_size)\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps =  1#@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
        "                                      inverse_scaler, snr, n_steps=n_steps,\n",
        "                                      probability_flow=probability_flow,\n",
        "                                      continuous=config.training.continuous,\n",
        "                                      eps=sampling_eps, device=config.device)\n",
        "\n",
        "x, n = sampling_fn(score_model)\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AdiQdwN2aFA"
      },
      "source": [
        "# Probability flow ODE\n",
        "\n",
        "With black-box ODE solvers, we can produce samples, compute likelihoods, and obtain a uniquely identifiable encoding of any data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "iLQDfFvHSIGn",
        "outputId": "f1888e8b-4e70-446d-d248-9f1c1b6a7916"
      },
      "outputs": [],
      "source": [
        "#@title ODE sampling\n",
        "\n",
        "shape = (batch_size, 3, 32, 32)\n",
        "sampling_fn = sampling.get_ode_sampler(sde,                                        \n",
        "                                       shape, \n",
        "                                       inverse_scaler,                                       \n",
        "                                       denoise=True, \n",
        "                                       eps=sampling_eps,\n",
        "                                       device=config.device)\n",
        "x, nfe = sampling_fn(score_model)\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MsdcLnhu7s46"
      },
      "outputs": [],
      "source": [
        "#@title Likelihood computation\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=True, evaluation=True)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "likelihood_fn = likelihood.get_likelihood_fn(sde,                                              \n",
        "                                             inverse_scaler,                                             \n",
        "                                             eps=1e-5)\n",
        "for batch in eval_iter:\n",
        "  img = batch['image']._numpy()\n",
        "  img = torch.tensor(img).permute(0, 3, 1, 2).to(config.device)\n",
        "  img = scaler(img)\n",
        "  bpd, z, nfe = likelihood_fn(score_model, img)\n",
        "  bpds.extend(bpd)\n",
        "  print(f\"average bpd: {torch.tensor(bpds).mean().item()}, NFE: {nfe}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "oe3rLGRm28nc",
        "outputId": "4d3b614b-df5b-4523-aa91-a223d6134397"
      },
      "outputs": [],
      "source": [
        "#@title Representations\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=False, evaluation=True)\n",
        "eval_batch = next(iter(eval_ds))\n",
        "eval_images = eval_batch['image']._numpy()\n",
        "shape = (batch_size, 3, 32, 32)\n",
        "\n",
        "likelihood_fn = likelihood.get_likelihood_fn(sde, inverse_scaler, eps=1e-5)\n",
        "sampling_fn = sampling.get_ode_sampler(sde, shape, inverse_scaler,\n",
        "                                       denoise=True, eps=sampling_eps, device=config.device)\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis('off')\n",
        "plt.imshow(image_grid(eval_images))\n",
        "plt.title('Original images')\n",
        "\n",
        "eval_images = torch.from_numpy(eval_images).permute(0, 3, 1, 2).to(config.device)\n",
        "_, latent_z, _ = likelihood_fn(score_model, scaler(eval_images))\n",
        "\n",
        "x, nfe = sampling_fn(score_model, latent_z)\n",
        "\n",
        "x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis('off')\n",
        "plt.imshow(image_grid(x))\n",
        "plt.title('Reconstructed images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaGYVD7KcoW6"
      },
      "source": [
        "# Controllable generation\n",
        "\n",
        "Several demonstrations on how to solve inverse problems with our SDE framework.\n",
        "\n",
        "Recommended settings\n",
        "\n",
        "| dataset | SDE | predictor | corrector | snr | n_steps |\n",
        "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
        "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
        "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
        "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
        "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
        "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbly_8RIjqJD",
        "outputId": "28ca290e-1079-4031-e37a-c69374398f76"
      },
      "outputs": [],
      "source": [
        "#@title PC inpainting\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps = 1 #@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "\n",
        "pc_inpainter = controllable_generation.get_pc_inpainter(sde,\n",
        "                                                        predictor, corrector,\n",
        "                                                        inverse_scaler,\n",
        "                                                        snr=snr,\n",
        "                                                        n_steps=n_steps,\n",
        "                                                        probability_flow=probability_flow,\n",
        "                                                        continuous=config.training.continuous,\n",
        "                                                        denoise=True)\n",
        "batch = next(eval_iter)\n",
        "img = batch['image']._numpy()\n",
        "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
        "show_samples(img)\n",
        "\n",
        "mask = torch.ones_like(img)\n",
        "mask[:, :, :, 16:] = 0.\n",
        "show_samples(img * mask)\n",
        "\n",
        "\n",
        "x = pc_inpainter(score_model, scaler(img), mask)\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DsP-ayb8cupk",
        "outputId": "51272ecd-4ba3-4931-8a6d-358c6218e25b"
      },
      "outputs": [],
      "source": [
        "#@title PC colorizer\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps = 1 #@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "\n",
        "batch = next(eval_iter)\n",
        "img = batch['image']._numpy()\n",
        "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
        "show_samples(img)\n",
        "gray_scale_img = torch.mean(img, dim=1, keepdims=True).repeat(1, 3, 1, 1)\n",
        "show_samples(gray_scale_img)\n",
        "gray_scale_img = scaler(gray_scale_img)\n",
        "pc_colorizer = controllable_generation.get_pc_colorizer(\n",
        "    sde, predictor, corrector, inverse_scaler,\n",
        "    snr=snr, n_steps=n_steps, probability_flow=probability_flow,\n",
        "    continuous=config.training.continuous, denoise=True\n",
        ")\n",
        "x = pc_colorizer(score_model, gray_scale_img)\n",
        "\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiYRNB-Wk329"
      },
      "source": [
        "## Class-conditional generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTu-5e6S68Gb"
      },
      "source": [
        "Check out the [class-conditional generation section](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55#scrollTo=HiYRNB-Wk329&line=3&uniqifier=1) in our [JAX demo](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55?usp=sharing)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Score SDE demo PyTorch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
